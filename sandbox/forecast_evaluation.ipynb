{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airsenal.framework.utils import *\n",
    "from airsenal.framework.bpl_interface import get_ratings_df\n",
    "\n",
    "import bpl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the team level model vs. a baseline\n",
    "\n",
    "Our baseline will be an independent poisson model, where the rates in the distribution of home and away goals are set by the mean values in the training data. All teams are treated equally.\n",
    "\n",
    "We will compare this baseline to the plain BPL model that doesn't use Fifa features, and to the BPL model that does use Fifa features.\n",
    "\n",
    "We train models on the 16/17 and test on the 17/18 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_df():\n",
    "    \"\"\"\n",
    "    query the match table and put results into pandas dataframe,\n",
    "    to train the team-level model.\n",
    "    \"\"\"\n",
    "    df_past = pd.DataFrame(\n",
    "        np.array(\n",
    "            [\n",
    "                [s.date, s.home_team, s.away_team, s.home_score, s.away_score]\n",
    "                for s in session.query(Match).all()\n",
    "            ]\n",
    "        ),\n",
    "        columns=[\"date\", \"home_team\", \"away_team\", \"home_goals\", \"away_goals\"],\n",
    "    )\n",
    "    df_past[\"home_goals\"] = df_past[\"home_goals\"].astype(int)\n",
    "    df_past[\"away_goals\"] = df_past[\"away_goals\"].astype(int)\n",
    "    df_past[\"date\"] = pd.to_datetime(df_past[\"date\"])\n",
    "    df_past = df_past[df_past[\"date\"] > \"2015-08-01\"]\n",
    "    return df_past.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_result_df()\n",
    "df_train = df[(df[\"date\"] >= \"2016-08-13\") & (df[\"date\"] < \"2017-08-10\")]\n",
    "df_test = df[(df[\"date\"] >= \"2017-08-10\")&(df[\"date\"] < \"2018-08-10\")]\n",
    "df_X = get_ratings_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.results = df\n",
    "        self.mu_home = df[\"home_goals\"].mean()\n",
    "        self.mu_away = df[\"away_goals\"].mean()\n",
    "    \n",
    "    def log_score(self, df_test):\n",
    "        home_probs = poisson.pmf(df_test[\"home_goals\"].values, self.mu_home)\n",
    "        away_probs = poisson.pmf(df_test[\"away_goals\"].values, self.mu_away)\n",
    "        return np.log(home_probs) + np.log(away_probs)\n",
    "    \n",
    "    def avg_log_score(self, df_test):\n",
    "        return np.mean(self.log_score(df_test))\n",
    "\n",
    "def bpl_log_score(bplmodel, df):\n",
    "    # calculate the log score of the model on some matches\n",
    "    pr_result = df.apply(\n",
    "        lambda row: bplmodel.score_probability(\n",
    "            row[\"home_team\"], row[\"away_team\"], row[\"home_goals\"], row[\"away_goals\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    return np.log(pr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineModel(df_train)\n",
    "baseline_score = baseline.log_score(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bpl.BPLModel(data=df_train)\n",
    "model.fit(max_date=\"2017-08-10\")\n",
    "\n",
    "model.add_new_team(\"NEW\")\n",
    "model.add_new_team(\"HUD\")\n",
    "model.add_new_team(\"BHA\")\n",
    "plain_score = bpl_log_score(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean difference in log score (+ive means BPL model achieves a higher score) \\n\"\n",
    "      \"between the BPL model and the baseline is {0:.2f} +/- {1:.2f}\".format(\n",
    "    np.mean(plain_score - baseline_score),\n",
    "    np.std(plain_score - baseline_score) / np.sqrt(len(plain_score))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_X = bpl.BPLModel(data=df_train, X=df_X)\n",
    "model_X.fit(max_date=\"2017-08-10\")\n",
    "\n",
    "model_X.add_new_team(\"NEW\",\n",
    "                   X=np.ravel(\n",
    "                       df_X.loc[df_X[\"team\"] == \"NEW\", [\"att\", \"mid\", \"defn\", \"ovr\"]].values\n",
    "                   ).astype(float)\n",
    "                  )\n",
    "model_X.add_new_team(\"HUD\",\n",
    "                   X=np.ravel(\n",
    "                       df_X.loc[df_X[\"team\"] == \"HUD\", [\"att\", \"mid\", \"defn\", \"ovr\"]].values\n",
    "                   ).astype(float)\n",
    "                  )\n",
    "model_X.add_new_team(\"BHA\",\n",
    "                   X=np.ravel(\n",
    "                       df_X.loc[df_X[\"team\"] == \"BHA\", [\"att\", \"mid\", \"defn\", \"ovr\"]].values\n",
    "                   ).astype(float)\n",
    "                  )\n",
    "fifa_score = bpl_log_score(model_X, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean difference in log score \"\n",
    "      \"between the BPL model with Fifa features and the BPL model without Fifa features is {0:.2f} +/- {1:.2f}\".format(\n",
    "    np.mean(fifa_score - plain_score),\n",
    "    np.std(fifa_score - plain_score) / np.sqrt(len(fifa_score))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranks of the models is as expected, with the BPL model with fifa features scoring best on holdout data. However, the difference between the two BPL models is markedly smaller than between the simpler BPL model and the baseline. Presumably the main difference comes from the matches involving Brighton, Huddersfield and Newcastle, where the fifa features model will perform better. Let's briefly check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hud_bha = df_test[(df_test[\"home_team\"] == \"BHA\") \n",
    "                     | (df_test[\"home_team\"] == \"HUD\")\n",
    "                     | (df_test[\"away_team\"] == \"BHA\")\n",
    "                     | (df_test[\"away_team\"] == \"BHA\")\n",
    "                     | (df_test[\"away_team\"] == \"NEW\")\n",
    "                     | (df_test[\"away_team\"] == \"NEW\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_score = bpl_log_score(model, df_hud_bha)\n",
    "fifa_score = bpl_log_score(model_X, df_hud_bha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean difference in log score \"\n",
    "      \"between the BPL model with Fifa features and the BPL model without Fifa features is {0:.2f} +/- {1:.2f}\".format(\n",
    "    np.mean(fifa_score - plain_score),\n",
    "    np.std(fifa_score - plain_score) / np.sqrt(len(fifa_score))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference does increase, as expected (though the standard error also increases as there are fewer matches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    sns.distplot(model_X.beta_a[:, i], label=df_X.columns[1:][i])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    sns.distplot(model_X.beta_b[:, i], label=df_X.columns[1:][i])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifa features provide rather weak information about the team aptitudes, but there is evidently some (weak) signal there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
